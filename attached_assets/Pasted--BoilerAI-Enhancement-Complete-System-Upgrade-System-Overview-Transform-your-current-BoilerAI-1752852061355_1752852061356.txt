# BoilerAI Enhancement - Complete System Upgrade

## System Overview
Transform your current BoilerAI system into a comprehensive, intelligent academic advisor that can answer ANY question about Purdue's CS department. This upgrade implements advanced NLP, expanded knowledge graphs, personalized recommendations, and continuous learning capabilities.

## 1. Enhanced Database Schema

### A. Expanded SQLite Database Structure
```sql
-- Enhanced course table
CREATE TABLE courses (
    code TEXT PRIMARY KEY,
    title TEXT,
    credits INTEGER,
    description TEXT,
    prerequisites TEXT,
    corequisites TEXT,
    semester_offered TEXT,
    difficulty_rating REAL DEFAULT 0.0,
    workload_hours INTEGER DEFAULT 0,
    grade_distribution TEXT, -- JSON format
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- New professors table
CREATE TABLE professors (
    professor_id TEXT PRIMARY KEY,
    name TEXT,
    email TEXT,
    office_location TEXT,
    office_hours TEXT,
    research_areas TEXT, -- JSON array
    courses_taught TEXT, -- JSON array of course codes
    ratemyprofessor_rating REAL DEFAULT 0.0,
    ratemyprofessor_difficulty REAL DEFAULT 0.0,
    department TEXT DEFAULT 'Computer Science',
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Academic policies table
CREATE TABLE policies (
    policy_id TEXT PRIMARY KEY,
    category TEXT, -- add_drop, transfer_credit, exemption, graduation
    title TEXT,
    description TEXT,
    applicable_courses TEXT, -- JSON array
    effective_date DATE,
    source_url TEXT,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Student resources table
CREATE TABLE resources (
    resource_id TEXT PRIMARY KEY,
    type TEXT, -- club, career_fair, tutoring, advising
    name TEXT,
    description TEXT,
    contact_info TEXT,
    meeting_times TEXT,
    location TEXT,
    website_url TEXT,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- User profiles for personalization
CREATE TABLE student_profiles (
    student_id TEXT PRIMARY KEY,
    year TEXT, -- freshman, sophomore, junior, senior
    major TEXT DEFAULT 'Computer Science',
    track TEXT, -- MI, SE, Graphics, etc.
    gpa REAL,
    completed_courses TEXT, -- JSON array
    current_courses TEXT, -- JSON array
    interests TEXT, -- JSON array
    career_goals TEXT,
    preferred_difficulty TEXT, -- easy, moderate, challenging
    max_credits_per_semester INTEGER DEFAULT 15,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Feedback and learning system
CREATE TABLE user_feedback (
    feedback_id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT,
    student_id TEXT,
    query TEXT,
    response TEXT,
    rating INTEGER, -- 1-5 scale
    feedback_text TEXT,
    intent_classification TEXT,
    response_time_ms INTEGER,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Session context for multi-turn conversations
CREATE TABLE session_context (
    session_id TEXT PRIMARY KEY,
    student_id TEXT,
    current_topic TEXT,
    conversation_history TEXT, -- JSON array
    extracted_context TEXT, -- JSON object
    last_activity DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Course relationships and dependencies
CREATE TABLE course_relationships (
    relationship_id INTEGER PRIMARY KEY AUTOINCREMENT,
    from_course TEXT,
    to_course TEXT,
    relationship_type TEXT, -- prerequisite, corequisite, recommended
    strength REAL DEFAULT 1.0, -- relationship strength
    FOREIGN KEY (from_course) REFERENCES courses(code),
    FOREIGN KEY (to_course) REFERENCES courses(code)
);

-- Course sections and scheduling
CREATE TABLE course_sections (
    section_id TEXT PRIMARY KEY,
    course_code TEXT,
    semester TEXT,
    year INTEGER,
    instructor TEXT,
    meeting_times TEXT, -- JSON array
    location TEXT,
    capacity INTEGER,
    enrolled INTEGER,
    waitlist_size INTEGER,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (course_code) REFERENCES courses(code),
    FOREIGN KEY (instructor) REFERENCES professors(professor_id)
);
```

## 2. Advanced Web Scraping System

### A. Multi-Source Data Scraper
```python
import requests
from bs4 import BeautifulSoup
import sqlite3
import json
import time
import re
from datetime import datetime
from urllib.parse import urljoin, urlparse
import logging

class PurdueDataScraper:
    def __init__(self, db_path="purdue_cs_knowledge.db"):
        self.db_path = db_path
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.base_urls = {
            'cs_undergraduate': 'https://www.cs.purdue.edu/undergraduate/index.html',
            'course_catalog': 'https://selfservice.mypurdue.purdue.edu/prod/bzwsrch.p_catalog_detail',
            'faculty': 'https://www.cs.purdue.edu/people/faculty',
            'policies': 'https://www.cs.purdue.edu/undergraduate/policies.html'
        }
        
    def scrape_course_details(self, course_code):
        """Scrape detailed course information from MyPurdue"""
        url = f"{self.base_urls['course_catalog']}?subject=CS&term=CURRENT&cnbr={course_code}"
        
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            course_info = {
                'code': f'CS {course_code}',
                'title': self.extract_course_title(soup),
                'credits': self.extract_credits(soup),
                'description': self.extract_description(soup),
                'prerequisites': self.extract_prerequisites(soup),
                'corequisites': self.extract_corequisites(soup),
                'semester_offered': self.extract_semester_offered(soup),
                'last_updated': datetime.now().isoformat()
            }
            
            return course_info
            
        except Exception as e:
            logging.error(f"Error scraping course {course_code}: {e}")
            return None
    
    def extract_course_title(self, soup):
        """Extract course title from soup"""
        title_element = soup.find('h1') or soup.find('h2') or soup.find('h3')
        if title_element:
            title_text = title_element.get_text(strip=True)
            # Remove course code from title
            title_text = re.sub(r'^CS\s*\d+\s*[-:]?\s*', '', title_text)
            return title_text
        return "Unknown Title"
    
    def extract_credits(self, soup):
        """Extract credit hours from soup"""
        credit_pattern = r'(\d+(?:\.\d+)?)\s*credit'
        text = soup.get_text()
        match = re.search(credit_pattern, text, re.IGNORECASE)
        return float(match.group(1)) if match else 3.0
    
    def extract_description(self, soup):
        """Extract course description"""
        # Look for description in various possible locations
        description_selectors = [
            'div.course-description',
            'p.description',
            'div.description',
            'td.description'
        ]
        
        for selector in description_selectors:
            desc_element = soup.select_one(selector)
            if desc_element:
                return desc_element.get_text(strip=True)
        
        # Fallback: look for text after "Description:" or similar
        text = soup.get_text()
        desc_match = re.search(r'Description:?\s*(.+?)(?:\n\n|Prerequisites:|$)', text, re.DOTALL | re.IGNORECASE)
        if desc_match:
            return desc_match.group(1).strip()
        
        return "No description available"
    
    def extract_prerequisites(self, soup):
        """Extract prerequisites from soup"""
        text = soup.get_text()
        prereq_pattern = r'Prerequisites?:?\s*(.+?)(?:\n\n|Corequisites?:|Course Description:|$)'
        match = re.search(prereq_pattern, text, re.DOTALL | re.IGNORECASE)
        
        if match:
            prereq_text = match.group(1).strip()
            # Extract CS course codes
            course_codes = re.findall(r'CS\s*(\d{5})', prereq_text)
            return [f'CS {code}' for code in course_codes]
        
        return []
    
    def extract_corequisites(self, soup):
        """Extract corequisites from soup"""
        text = soup.get_text()
        coreq_pattern = r'Corequisites?:?\s*(.+?)(?:\n\n|Prerequisites?:|Course Description:|$)'
        match = re.search(coreq_pattern, text, re.DOTALL | re.IGNORECASE)
        
        if match:
            coreq_text = match.group(1).strip()
            course_codes = re.findall(r'CS\s*(\d{5})', coreq_text)
            return [f'CS {code}' for code in course_codes]
        
        return []
    
    def extract_semester_offered(self, soup):
        """Extract semester offering information"""
        text = soup.get_text()
        if 'fall' in text.lower() and 'spring' in text.lower():
            return 'Fall, Spring'
        elif 'fall' in text.lower():
            return 'Fall'
        elif 'spring' in text.lower():
            return 'Spring'
        elif 'summer' in text.lower():
            return 'Summer'
        else:
            return 'Unknown'
    
    def scrape_faculty_info(self):
        """Scrape faculty information from CS department"""
        url = self.base_urls['faculty']
        
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            faculty_list = []
            faculty_elements = soup.find_all('div', class_='faculty-member') or soup.find_all('div', class_='person')
            
            for element in faculty_elements:
                faculty_info = {
                    'name': self.extract_faculty_name(element),
                    'email': self.extract_faculty_email(element),
                    'office_location': self.extract_faculty_office(element),
                    'research_areas': self.extract_research_areas(element),
                    'last_updated': datetime.now().isoformat()
                }
                faculty_list.append(faculty_info)
            
            return faculty_list
            
        except Exception as e:
            logging.error(f"Error scraping faculty: {e}")
            return []
    
    def extract_faculty_name(self, element):
        """Extract faculty name from element"""
        name_element = element.find('h3') or element.find('h2') or element.find('h4')
        if name_element:
            return name_element.get_text(strip=True)
        return "Unknown"
    
    def extract_faculty_email(self, element):
        """Extract faculty email from element"""
        email_element = element.find('a', href=re.compile(r'mailto:'))
        if email_element:
            return email_element.get('href').replace('mailto:', '')
        return ""
    
    def extract_faculty_office(self, element):
        """Extract faculty office location"""
        office_pattern = r'Office:?\s*([^,\n]+)'
        text = element.get_text()
        match = re.search(office_pattern, text, re.IGNORECASE)
        return match.group(1).strip() if match else ""
    
    def extract_research_areas(self, element):
        """Extract research areas from faculty element"""
        research_pattern = r'Research:?\s*(.+?)(?:\n\n|Office:|Email:|$)'
        text = element.get_text()
        match = re.search(research_pattern, text, re.DOTALL | re.IGNORECASE)
        
        if match:
            research_text = match.group(1).strip()
            # Split by common delimiters
            areas = re.split(r'[,;]', research_text)
            return [area.strip() for area in areas if area.strip()]
        
        return []
    
    def save_to_database(self, data_type, data):
        """Save scraped data to SQLite database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if data_type == 'course':
            cursor.execute('''
                INSERT OR REPLACE INTO courses 
                (code, title, credits, description, prerequisites, corequisites, semester_offered, last_updated)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                data['code'], data['title'], data['credits'], data['description'],
                json.dumps(data['prerequisites']), json.dumps(data['corequisites']),
                data['semester_offered'], data['last_updated']
            ))
        
        elif data_type == 'professor':
            cursor.execute('''
                INSERT OR REPLACE INTO professors 
                (professor_id, name, email, office_location, research_areas, last_updated)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                data['name'].replace(' ', '_').lower(), data['name'], data['email'],
                data['office_location'], json.dumps(data['research_areas']),
                data['last_updated']
            ))
        
        conn.commit()
        conn.close()
    
    def run_comprehensive_scrape(self):
        """Run complete scraping process"""
        logging.info("Starting comprehensive scraping process...")
        
        # Scrape core CS courses
        core_courses = ['18000', '18200', '24000', '25000', '25100', '25200']
        
        for course_code in core_courses:
            logging.info(f"Scraping CS {course_code}...")
            course_info = self.scrape_course_details(course_code)
            if course_info:
                self.save_to_database('course', course_info)
            time.sleep(1)  # Be respectful with requests
        
        # Scrape faculty information
        logging.info("Scraping faculty information...")
        faculty_list = self.scrape_faculty_info()
        for faculty in faculty_list:
            self.save_to_database('professor', faculty)
        
        logging.info("Scraping completed successfully!")
```

## 3. Enhanced Knowledge Graph System

### A. Advanced NetworkX Graph Implementation
```python
import networkx as nx
import sqlite3
import json
from typing import Dict, List, Optional, Tuple

class EnhancedKnowledgeGraph:
    def __init__(self, db_path="purdue_cs_knowledge.db"):
        self.db_path = db_path
        self.graph = nx.DiGraph()
        self.node_types = {
            'course': 'lightblue',
            'professor': 'lightgreen',
            'track': 'orange',
            'policy': 'pink',
            'resource': 'yellow'
        }
        self.build_graph()
    
    def build_graph(self):
        """Build comprehensive knowledge graph from database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Add course nodes
        cursor.execute("SELECT code, title, credits, difficulty_rating FROM courses")
        courses = cursor.fetchall()
        
        for code, title, credits, difficulty in courses:
            self.graph.add_node(code, 
                              type='course',
                              title=title,
                              credits=credits,
                              difficulty=difficulty or 3.0)
        
        # Add professor nodes
        cursor.execute("SELECT professor_id, name, research_areas FROM professors")
        professors = cursor.fetchall()
        
        for prof_id, name, research_areas in professors:
            research_list = json.loads(research_areas) if research_areas else []
            self.graph.add_node(prof_id,
                              type='professor',
                              name=name,
                              research_areas=research_list)
        
        # Add track nodes
        tracks = ['Machine Intelligence', 'Software Engineering', 'Computer Graphics',
                 'Database Systems', 'Security', 'Systems Software', 'Programming Languages',
                 'Algorithmic Foundations', 'Computational Science']
        
        for track in tracks:
            self.graph.add_node(track.replace(' ', '_').lower(),
                              type='track',
                              name=track)
        
        # Add prerequisite edges
        cursor.execute("SELECT from_course, to_course, relationship_type FROM course_relationships")
        relationships = cursor.fetchall()
        
        for from_course, to_course, rel_type in relationships:
            self.graph.add_edge(from_course, to_course, relationship=rel_type)
        
        # Add professor-course relationships
        cursor.execute("SELECT professor_id, courses_taught FROM professors WHERE courses_taught IS NOT NULL")
        prof_courses = cursor.fetchall()
        
        for prof_id, courses_taught in prof_courses:
            if courses_taught:
                course_list = json.loads(courses_taught)
                for course in course_list:
                    self.graph.add_edge(prof_id, course, relationship='teaches')
        
        conn.close()
    
    def find_prerequisites(self, course_code: str) -> List[str]:
        """Find all prerequisites for a course"""
        prerequisites = []
        for predecessor in self.graph.predecessors(course_code):
            edge_data = self.graph.get_edge_data(predecessor, course_code)
            if edge_data and edge_data.get('relationship') == 'prerequisite':
                prerequisites.append(predecessor)
        return prerequisites
    
    def find_course_professors(self, course_code: str) -> List[Dict]:
        """Find all professors who teach a course"""
        professors = []
        for predecessor in self.graph.predecessors(course_code):
            if self.graph.nodes[predecessor].get('type') == 'professor':
                prof_data = self.graph.nodes[predecessor]
                professors.append({
                    'id': predecessor,
                    'name': prof_data.get('name'),
                    'research_areas': prof_data.get('research_areas', [])
                })
        return professors
    
    def find_track_courses(self, track_name: str) -> List[str]:
        """Find all courses in a specific track"""
        track_id = track_name.replace(' ', '_').lower()
        courses = []
        for successor in self.graph.successors(track_id):
            if self.graph.nodes[successor].get('type') == 'course':
                courses.append(successor)
        return courses
    
    def recommend_next_courses(self, completed_courses: List[str], track: str = None) -> List[str]:
        """Recommend next courses based on completed courses"""
        available_courses = []
        
        for course in self.graph.nodes():
            if self.graph.nodes[course].get('type') != 'course':
                continue
            
            if course in completed_courses:
                continue
            
            # Check if prerequisites are satisfied
            prerequisites = self.find_prerequisites(course)
            if all(prereq in completed_courses for prereq in prerequisites):
                available_courses.append(course)
        
        # Filter by track if specified
        if track:
            track_courses = self.find_track_courses(track)
            available_courses = [c for c in available_courses if c in track_courses]
        
        return available_courses[:5]  # Return top 5 recommendations
    
    def find_graduation_path(self, completed_courses: List[str], target_courses: List[str]) -> List[List[str]]:
        """Find optimal path to complete target courses"""
        paths = []
        
        for target in target_courses:
            if target in completed_courses:
                continue
            
            # Find shortest path considering prerequisites
            try:
                path = nx.shortest_path(self.graph, source='start', target=target)
                # Filter out completed courses from path
                remaining_path = [c for c in path if c not in completed_courses]
                if remaining_path:
                    paths.append(remaining_path)
            except nx.NetworkXNoPath:
                # If no path exists, add course individually
                paths.append([target])
        
        return paths
    
    def calculate_course_difficulty(self, course_list: List[str]) -> float:
        """Calculate average difficulty of a course list"""
        total_difficulty = 0
        count = 0
        
        for course in course_list:
            if course in self.graph.nodes():
                difficulty = self.graph.nodes[course].get('difficulty', 3.0)
                total_difficulty += difficulty
                count += 1
        
        return total_difficulty / count if count > 0 else 3.0
    
    def optimize_semester_schedule(self, available_courses: List[str], max_credits: int = 15) -> Dict:
        """Optimize course selection for a semester"""
        # Sort courses by priority (difficulty, prerequisites satisfied, etc.)
        course_scores = []
        
        for course in available_courses:
            if course not in self.graph.nodes():
                continue
            
            node_data = self.graph.nodes[course]
            credits = node_data.get('credits', 3)
            difficulty = node_data.get('difficulty', 3.0)
            
            # Calculate priority score (lower is better)
            priority_score = difficulty * 0.3 + credits * 0.2
            
            course_scores.append({
                'course': course,
                'credits': credits,
                'difficulty': difficulty,
                'priority': priority_score
            })
        
        # Sort by priority
        course_scores.sort(key=lambda x: x['priority'])
        
        # Select courses within credit limit
        selected_courses = []
        total_credits = 0
        
        for course_info in course_scores:
            if total_credits + course_info['credits'] <= max_credits:
                selected_courses.append(course_info)
                total_credits += course_info['credits']
        
        return {
            'selected_courses': selected_courses,
            'total_credits': total_credits,
            'avg_difficulty': sum(c['difficulty'] for c in selected_courses) / len(selected_courses) if selected_courses else 0
        }
```

## 4. Advanced NLP and Context System

### A. GPT-4o Integration with Context Awareness
```python
import openai
import json
import re
from typing import Dict, List, Optional
import sqlite3
from datetime import datetime

class AdvancedNLPProcessor:
    def __init__(self, api_key: str, db_path: str = "purdue_cs_knowledge.db"):
        self.client = openai.OpenAI(api_key=api_key)
        self.db_path = db_path
        self.intent_patterns = {
            'course_info': [
                r'what is (cs|CS) ?\d+',
                r'tell me about (cs|CS) ?\d+',
                r'course description',
                r'about (cs|CS) ?\d+'
            ],
            'professor_info': [
                r'who teaches',
                r'professor for',
                r'best prof',
                r'instructor',
                r'faculty'
            ],
            'prerequisite_query': [
                r'prerequisites?',
                r'prereq',
                r'requirements? for',
                r'need to take before',
                r'depends on'
            ],
            'course_recommendation': [
                r'what should I take',
                r'recommend',
                r'suggest',
                r'next course',
                r'best course'
            ],
            'difficulty_inquiry': [
                r'how hard',
                r'how difficult',
                r'difficulty',
                r'challenging',
                r'tough'
            ],
            'career_guidance': [
                r'career',
                r'job',
                r'internship',
                r'work',
                r'industry'
            ],
            'policy_question': [
                r'policy',
                r'rule',
                r'regulation',
                r'can I',
                r'allowed to'
            ],
            'schedule_planning': [
                r'schedule',
                r'semester',
                r'credit',
                r'workload',
                r'balance'
            ]
        }
    
    def extract_context_with_gpt4o(self, query: str, conversation_history: List[Dict] = None) -> Dict:
        """Extract structured context from user query using GPT-4o"""
        
        context_prompt = f"""
        Analyze the following query and extract structured information:
        
        Query: "{query}"
        
        Conversation History: {json.dumps(conversation_history[-3:] if conversation_history else [])}
        
        Extract and return a JSON object with the following structure:
        {{
            "course_codes": ["CS XXXXX", ...],
            "student_year": "freshman|sophomore|junior|senior|graduate|unknown",
            "track_interest": "machine_intelligence|software_engineering|graphics|security|database|unknown",
            "difficulty_preference": "easy|moderate|challenging|unknown",
            "urgency": "high|medium|low",
            "question_type": "what|how|when|where|why|who",
            "main_intent": "course_info|professor_info|prerequisite_query|course_recommendation|difficulty_inquiry|career_guidance|policy_question|schedule_planning",
            "specific_concerns": ["concern1", "concern2", ...],
            "context_from_history": "what topic or course was discussed recently",
            "entities": ["entity1", "entity2", ...],
            "sentiment": "positive|negative|neutral|confused|frustrated"
        }}
        
        Only return the JSON object, no additional text.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an expert at extracting structured information from academic queries. Always return valid JSON."},
                    {"role": "user", "content": context_prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            context_json = response.choices[0].message.content.strip()
            # Remove markdown formatting if present
            context_json = re.sub(r'```json\s*|\s*```', '', context_json)
            
            return json.loads(context_json)
            
        except Exception as e:
            print(f"Error extracting context: {e}")
            return self.fallback_context_extraction(query)
    
    def fallback_context_extraction(self, query: str) -> Dict:
        """Fallback context extraction using regex patterns"""
        context = {
            "course_codes": [],
            "student_year": "unknown",
            "track_interest": "unknown",
            "difficulty_preference": "unknown",
            "urgency": "medium",
            "question_type": "unknown",
            "main_intent": "general_inquiry",
            "specific_concerns": [],
            "context_from_history": "",
            "entities": [],
            "sentiment": "neutral"
        }
        
        # Extract course codes
        course_pattern = r'(CS|cs)\s*(\d{5})'
        matches = re.findall(course_pattern, query)
        context["course_codes"] = [f"CS {match[1]}" for match in matches]
        
        # Determine student year
        year_patterns = {
            "freshman": r'\b(freshman|fresh|first year|1st year)\b',
            "sophomore": r'\b(sophomore|soph|second year|2nd year)\b',
            "junior": r'\b(junior|third year|3rd year)\b',
            "senior": r'\b(senior|fourth year|4th year)\b'
        }
        
        for year, pattern in year_patterns.items():
            if re.search(pattern, query, re.IGNORECASE):
                context["student_year"] = year
                break
        
        # Determine main intent
        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query, re.IGNORECASE):
                    context["main_intent"] = intent
                    break
            if context["main_intent"] != "general_inquiry":
                break
        
        # Extract question type
        question_words = {
            "what": r'\bwhat\b',
            "how": r'\bhow\b',
            "when": r'\bwhen\b',
            "where": r'\bwhere\b',
            "why": r'\bwhy\b',
            "who": r'\bwho\b'
        }
        
        for q_type, pattern in question_words.items():
            if re.search(pattern, query, re.IGNORECASE):
                context["question_type"] = q_type
                break
        
        return context
    
    def classify_intent(self, query: str, context: Dict) -> str:
        """Classify user intent based on query and context"""
        
        # Use GPT-4o context if available
        if context.get("main_intent") and context["main_intent"] != "general_inquiry":
            return context["main_intent"]
        
        # Fallback to pattern matching
        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query, re.IGNORECASE):
                    return intent
        
        return "general_inquiry"
    
    def generate_smart_response(self, query: str, context: Dict, knowledge_data: Dict) -> str:
        """Generate intelligent response using GPT-4o with context and knowledge"""
        
        system_prompt = """
        You are BoilerAI, an intelligent academic advisor for Purdue University's Computer Science department.
        
        Your capabilities:
        - Provide accurate, personalized academic advice
        - Answer questions about courses, prerequisites, professors, and policies
        - Recommend optimal course sequences and career paths
        - Maintain conversation context and provide follow-up assistance
        
        Guidelines:
        - Be encouraging and supportive
        - Provide specific, actionable advice
        - Reference actual Purdue CS data when available
        - Ask clarifying questions when needed
        - Maintain a conversational, friendly tone
        """
        
        user_prompt = f"""
        User Query: "{query}"
        
        Extracted Context: {json.dumps(context, indent=2)}
        
        Available Knowledge: {json.dumps(knowledge_data, indent=2)}
        
        Generate a comprehensive, personalized response that:
        1. Directly addresses the user's question
        2. Uses the provided context to personalize the response
        3. Incorporates relevant knowledge data
        4. Provides actionable next steps
        5. Maintains an encouraging, supportive tone
        
        If the query is unclear or needs more information, ask specific clarifying questions.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generating response: {e}")
            return "I apologize, but I'm having trouble processing your request right now. Could you please try rephrasing your question?"
    
    def save_conversation_context(self, session_id: str, query: str, response: str, context: Dict):
        """Save conversation context to database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get existing conversation history
        cursor.execute("SELECT conversation_history FROM session_context WHERE session_id = ?", (session_id,))
        result = cursor.fetchone()
        
        if result:
            history = json.loads(result[0]) if result[0] else []
        else:
            history = []
        
        # Add new interaction
        history.append({
            "query": query,
            "response": response,
            "context": context,
            "timestamp": datetime.now().isoformat()
        })
        
        # Keep only last 10 interactions
        history = history[-10:]
        
        # Update database
        cursor.execute("""
            INSERT OR REPLACE INTO session_context 
            (session_id, current_topic, conversation_history, extracted_context, last_activity)
            VALUES (?, ?, ?, ?, ?)
        """, (
            session_id,
            context.get("main_intent", "general"),
            json.dumps(history),
            json.dumps(context),
            datetime.now().isoformat()
        ))
        
        conn.commit()
        conn.close()
```

## 5. Query Processing Engine

### A. Intelligent Query Router
```python
class QueryProcessor:
    def __init__(self, db_path: str = "purdue_cs_knowledge.db"):
        self.db_path = db_path
        self.knowledge_graph = EnhancedKnowledgeGraph(db_path)
        self.nlp_processor = AdvancedNLPProcessor("your-openai-api-key", db_path)
        
    def process_query(self, query: str, session_id: str = None, student_id: str = None) -> Dict:
        """Main query processing pipeline"""
        
        # Get conversation history
        conversation_history = self.get_conversation_history(session_id) if session_id else []
        
        # Extract context using GPT-4o
        context = self.nlp_processor.extract_context_with_gpt4o(query, conversation_history)
        
        # Classify intent
        intent = self.nlp_processor.classify_intent(query, context)
        
        # Route to appropriate handler
        handler_map = {
            'course_info': self.handle_course_info,
            'professor_info': self.handle_professor_info,
            'prerequisite_query': self.handle_prerequisite_query,
            'course_recommendation': self.handle_course_recommendation,
            'difficulty_inquiry': self.handle_difficulty_inquiry,
            'career_guidance': self.handle_career_guidance,
            'policy_question': self.handle_policy_question,
            'schedule_planning': self.handle_schedule_planning
        }
        
        handler = handler_map.get(intent, self.handle_general_inquiry)
        knowledge_data = handler(query, context, student_id)
        
        # Generate response using GPT-4o
        response = self.nlp_processor.generate_smart_response(query, context, knowledge_data)
        
        # Save conversation context
        if session_id:
            self.nlp_processor.save_conversation_context(session_id, query, response, context)
        
        return {
            'query': query,
            'response': response,
            'intent': intent,
            'context': context,
            'knowledge_data': knowledge_data,
            'session_id': session_id
        }
    
    def handle_course_info(self, query: str, context: Dict, student_id: str = None) -> Dict:
        """Handle course information queries"""
        knowledge_data = {'courses': [], 'related_info': {}}
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get course information
        for course_code in context.get('course_codes', []):
            cursor.execute("""
                SELECT code, title, credits, description, prerequisites, 
                       difficulty_rating, semester_offered
                FROM courses WHERE code = ?
            """, (course_code,))
            
            result = cursor.fetchone()
            if result:
                course_info = {
                    'code': result[0],
                    'title': result[1],
                    'credits': result[2],
                    'description': result[3],
                    'prerequisites': json.loads(result[4]) if result[4] else [],
                    'difficulty_rating': result[5],
                    'semester_offered': result[6]
                }
                
                # Get professors who teach this course
                professors = self.knowledge_graph.find_course_professors(course_code)
                course_info['professors'] = professors
                
                knowledge_data['courses'].append(course_info)
        
        conn.close()
        return knowledge_data
    
    def handle_professor_info(self, query: str, context: Dict, student_id: str = None) -> Dict:
        """Handle professor information queries"""
        knowledge_data = {'professors': [], 'courses': []}
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # If specific course mentioned, find professors for that course
        if context.get('course_codes'):
            for course_code in context['course_codes']:
                professors = self.knowledge_graph.find_course_professors(course_code)
                knowledge_data['professors'].extend(professors)
        else:
            # General professor search
            cursor.execute("""
                SELECT professor_id, name, email, office_location, 
                       research_areas, ratemyprofessor_rating
                FROM professors
                LIMIT 10
            """)
            
            results = cursor.fetchall()
            for result in results:
                prof_info = {
                    'id': result[0],
                    'name': result[1],
                    'email': result[2],
                    'office_location': result[3],
                    'research_areas': json.loads(result[4]) if result[4] else [],
                    'rating': result[5]
                }
                knowledge_data['professors'].append(prof_info)
        
        conn.close()
        return knowledge_data
    
    def handle_course_recommendation(self, query: str, context: Dict, student_id: str = None) -> Dict:
        """Handle course recommendation queries"""
        knowledge_data = {'recommendations': [], 'reasoning': []}
        
        # Get student profile if available
        student_profile = self.get_student_profile(student_id) if student_id else None
        
        # Determine completed courses
        completed_courses = []
        if student_profile:
            completed_courses = json.loads(student_profile.get('completed_courses', '[]'))
        
        # Get track preference
        track = context.get('track_interest', 'unknown')
        if track == 'unknown' and student_profile:
            track = student_profile.get('track', 'unknown')
        
        # Get recommendations from knowledge graph
        recommendations = self.knowledge_graph.recommend_next_courses(
            completed_courses, track if track != 'unknown' else None
        )
        
        # Get detailed information for each recommendation
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for course_code in recommendations:
            cursor.execute("""
                SELECT code, title, credits, description, difficulty_rating, semester_offered
                FROM courses WHERE code = ?
            """, (course_code,))
            
            result = cursor.fetchone()
            if result:
                course_info = {
                    'code': result[0],
                    'title': result[1],
                    'credits': result[2],
                    'description': result[3],
                    'difficulty_rating': result[4],
                    'semester_offered': result[5]
                }
                knowledge_data['recommendations'].append(course_info)
        
        conn.close()
        return knowledge_data
    
    def handle_schedule_planning(self, query: str, context: Dict, student_id: str = None) -> Dict:
        """Handle schedule planning queries"""
        knowledge_data = {'schedule_options': [], 'optimization_tips': []}
        
        # Get student profile
        student_profile = self.get_student_profile(student_id) if student_id else None
        
        # Get available courses
        completed_courses = []
        max_credits = 15
        
        if student_profile:
            completed_courses = json.loads(student_profile.get('completed_courses', '[]'))
            max_credits = student_profile.get('max_credits_per_semester', 15)
        
        # Get course recommendations
        available_courses = self.knowledge_graph.recommend_next_courses(completed_courses)
        
        # Optimize schedule
        schedule_optimization = self.knowledge_graph.optimize_semester_schedule(
            available_courses, max_credits
        )
        
        knowledge_data['schedule_options'] = [schedule_optimization]
        knowledge_data['optimization_tips'] = [
            "Balance difficult courses with easier ones",
            "Consider prerequisite chains for future semesters",
            "Check professor ratings and teaching quality",
            "Account for time conflicts and location changes"
        ]
        
        return knowledge_data
    
    def get_student_profile(self, student_id: str) -> Dict:
        """Get student profile from database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT year, major, track, gpa, completed_courses, 
                   max_credits_per_semester, preferred_difficulty
            FROM student_profiles WHERE student_id = ?
        """, (student_id,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            return {
                'year': result[0],
                'major': result[1],
                'track': result[2],
                'gpa': result[3],
                'completed_courses': result[4],
                'max_credits_per_semester': result[5],
                'preferred_difficulty': result[6]
            }
        
        return None
    
    def get_conversation_history(self, session_id: str) -> List[Dict]:
        """Get conversation history from database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT conversation_history FROM session_context 
            WHERE session_id = ?
        """, (session_id,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result and result[0]:
            return json.loads(result[0])
        
        return []
```

## 6. Implementation Instructions

### A. Setup and Installation
```bash
# Install required packages
pip install requests beautifulsoup4 sqlite3 networkx openai numpy pandas lxml

# Create directory structure
mkdir boilerai_enhanced
cd boilerai_enhanced
mkdir data scrapers processors utils

# Create main application file
touch main.py
touch config.py
touch database_setup.py
```

### B. Main Application Entry Point
```python
# main.py
import sqlite3
import logging
from datetime import datetime
from scrapers.purdue_scraper import PurdueDataScraper
from processors.query_processor import QueryProcessor
from processors.knowledge_graph import EnhancedKnowledgeGraph
from utils.database_setup import setup_database

def main():
    # Setup logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # Setup database
    db_path = "purdue_cs_knowledge.db"
    setup_database(db_path)
    
    # Initialize scraper and run initial data collection
    scraper = PurdueDataScraper(db_path)
    scraper.run_comprehensive_scrape()
    
    # Initialize query processor
    processor = QueryProcessor(db_path)
    
    # CLI Interface
    print("üéì Welcome to Enhanced BoilerAI!")
    print("Ask me anything about Purdue CS - courses, professors, career advice, and more!")
    print("Type 'quit' to exit.\n")
    
    session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    while True:
        try:
            query = input("You: ").strip()
            
            if query.lower() in ['quit', 'exit', 'bye']:
                print("üéâ Thanks for using BoilerAI! Good luck with your academic journey!")
                break
            
            if not query:
                continue
            
            # Process query
            print("ü§î Processing your question...")
            result = processor.process_query(query, session_id)
            
            # Display response
            print(f"\nüéØ BoilerAI: {result['response']}\n")
            
        except KeyboardInterrupt:
            print("\n\nüëã Thanks for using BoilerAI!")
            break
        except Exception as e:
            print(f"‚ùå Error: {e}")
            print("Please try rephrasing your question.\n")

if __name__ == "__main__":
    main()
```

### C. Configuration File
```python
# config.py
import os

class Config:
    # Database configuration
    DATABASE_PATH = "purdue_cs_knowledge.db"
    
    # OpenAI API configuration
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key-here")
    
    # Scraping configuration
    SCRAPING_DELAY = 1  # seconds between requests
    MAX_RETRIES = 3
    REQUEST_TIMEOUT = 10
    
    # URLs for scraping
    PURDUE_URLS = {
        'cs_undergraduate': 'https://www.cs.purdue.edu/undergraduate/index.html',
        'course_catalog_base': 'https://selfservice.mypurdue.purdue.edu/prod/bzwsrch.p_catalog_detail',
        'faculty': 'https://www.cs.purdue.edu/people/faculty',
        'policies': 'https://www.cs.purdue.edu/undergraduate/policies.html'
    }
    
    # Core courses to scrape
    CORE_COURSES = ['18000', '18200', '24000', '25000', '25100', '25200']
    
    # Logging configuration
    LOG_LEVEL = "INFO"
    LOG_FORMAT = "%(asctime)s - %(levelname)s - %(message)s"
```

### D. Database Setup Utility
```python
# utils/database_setup.py
import sqlite3
import logging

def setup_database(db_path: str):
    """Setup complete database schema"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Execute all table creation statements from the schema above
    tables = [
        """CREATE TABLE IF NOT EXISTS courses (
            code TEXT PRIMARY KEY,
            title TEXT,
            credits INTEGER,
            description TEXT,
            prerequisites TEXT,
            corequisites TEXT,
            semester_offered TEXT,
            difficulty_rating REAL DEFAULT 0.0,
            workload_hours INTEGER DEFAULT 0,
            grade_distribution TEXT,
            last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
        )""",
        
        """CREATE TABLE IF NOT EXISTS professors (
            professor_id TEXT PRIMARY KEY,
            name TEXT,
            email TEXT,
            office_location TEXT,
            office_hours TEXT,
            research_areas TEXT,
            courses_taught TEXT,
            ratemyprofessor_rating REAL DEFAULT 0.0,
            ratemyprofessor_difficulty REAL DEFAULT 0.0,
            department TEXT DEFAULT 'Computer Science',
            last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
        )""",
        
        # Add all other table creation statements here...
    ]
    
    for table_sql in tables:
        cursor.execute(table_sql)
    
    conn.commit()
    conn.close()
    logging.info(f"Database setup complete: {db_path}")
```

## 7. Testing and Validation

### A. Test the Enhanced System
```python
# test_queries.py
test_queries = [
    "What is CS 18000?",
    "Who teaches CS 25100?",
    "I'm a sophomore interested in AI, what courses should I take?",
    "How difficult is CS 38100?",
    "What are the prerequisites for CS 25200?",
    "Can you recommend a good schedule for next semester?",
    "What's the difference between CS 18000 and CS 18200?",
    "I'm struggling with programming, what resources are available?",
    "What career paths are available after graduating?",
    "How do I get involved in CS research?",
    "What's the policy on adding courses late?",
    "Who are the best professors in the AI track?",
    "How do I plan my courses to graduate in 4 years?",
    "What's the workload like for CS courses?",
    "Can I skip CS 18000 with programming experience?"
]

def test_system():
    processor = QueryProcessor("purdue_cs_knowledge.db")
    
    for query in test_queries:
        print(f"\nüß™ Testing: {query}")
        result = processor.process_query(query)
        print(f"Intent: {result['intent']}")
        print(f"Response: {result['response'][:200]}...")
        print("-" * 50)
```

This comprehensive system transforms your BoilerAI into a truly intelligent academic advisor that can handle ANY question about Purdue CS with context-aware, personalized responses.